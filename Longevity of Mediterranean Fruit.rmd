### Longevity of Mediterranean Fruit flies (ex. 5.1.3 BIDA)

Carey et al. (1998) studied the ``cost of reproduction"
on longevity of Mediterranean fruit flies (medflies).
We use data from the 534 medflies that lived at least 34 days. 
These are cross-classified by two factors: A) whether the fly produced at
least 1,000 eggs in its first 30 days of life and B) whether the fly lived at least 44 days.

|       | Long-Lived | Short-Lived |
| ----- |:----------:| :-----:|
|High  | 54 | 80 |
| Low | 224 | 176    


These are clearly multinomial data but since our interest is in using the reproductive factor to
explain the response factor longevity, it makes sense to condition the observations on their observed reproductive factor. Hence, we are interested in  the probability of long lifetimes for high early-life egg producers and low early-life egg producers, respectively.




```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(R2jags)
```

```{r}
jags.data=list(n=c(134,400), y=c(54,224))

bin.model <- "model{ 
  y[1] ~ dbin(theta[1],n[1]) 
  y[2] ~ dbin(theta[2],n[2])
  theta[1] ~ dbeta(a1,b1) 
  theta[2] ~ dbeta(a2,b2) 
  RD=theta[2]-theta[1] 
  RR=theta[2]/theta[1] 
  test_RD=step(RD)
  test_RR=step(RR-1)
}"


jags.param=c("theta", "RR", "RD", "test_RD", "test_RR")
hyper=list(a1=1,b1=1,a2=1,b2=1)

jagsfit=jags(data=append(jags.data, hyper), n.chains=1, 
                parameters.to.save=jags.param, n.iter=5000, n.burnin=1000, 
                DIC=TRUE, model.file=textConnection(bin.model))
jagsfit
```

### Use of the Jeffreys' prior

Remember that the Jeffreys' prior is a *default* prior is a $Beta(0.5, 0.5)$

```{r}
jags.data=list(n=c(134,400), y=c(54,224))

bin.model <- "model{ 
  y[1] ~ dbin(theta[1],n[1]) 
  y[2] ~ dbin(theta[2],n[2])
  theta[1] ~ dbeta(a1,b1) 
  theta[2] ~ dbeta(a2,b2) 
  RD=theta[2]-theta[1] 
  RR=theta[2]/theta[1] 
  test_RD=step(RD)
  test_RR=step(RR-1)
}"


jags.param=c("theta", "RR", "RD", "test_RD", "test_RR")
hyper=list(a1=0.5,b1=0.5,a2=0.5,b2=0.5)

jagsfit=jags(data=append(jags.data, hyper), n.chains=1, 
                parameters.to.save=jags.param, n.iter=5000, n.burnin=1000, 
                DIC=TRUE, model.file=textConnection(bin.model))
jagsfit
```

### Reye’s Syndrome (RS)

In the late 1970s, it was observed that, in a sample of $n_1 = 7$ children with
Reye’s Syndrome (RS), all 7 of them were taking aspirin at the time they became sick. A second
sample of size $n_2 = 16$ children known to be free of Reye’s Syndrome was also taken, and it was
determined that 8 of them were taking aspirin when sampled. For more details on these data, see
Gastwirth (1988, Vol. 2).


The problem with case-control sampling is that we want to study
 the probabilities that children develop RS given them taking aspirin, but what the data allow us to study are the probabilities of taking asping given their RS status.
 
 
That is, let exposure variable $E=1$ if taking aspirin, $E=2$ if not
and similarly $D=1$ indicates RS is present, $D=2$ indicates RS not present. From our data, we can estimate

$$
\theta_1=P(E=1|D=1) \qquad \theta_2=P(E=1|D=2)
$$

but we would like to know
$$
RR=\frac{P(D=1|E=1)}{P(D=1|E=2)}
$$
The **odds ratio** of developing RS when taking aspirin relative to developing RS when not taking aspirin turns out to equal the odds ratio of taking aspirin when having RS relative to taking aspirin when not having RS
$$
OR=\frac{\frac{\theta_1}{1-\theta_1}}{\frac{\theta_2}{1-\theta_2}}=\frac{\frac{P(E=1|D=1)}{P(E=2|D=1)}}{\frac{P(E=1|D=2)}{P(E=2|D=2)}}=\frac{\frac{P(D=1|E=1)\, P(E=1)}{P(D=1|E=2)P(E=2)} }{\frac{P(D=2|E=1)P(E=1)}{P(D=2|E=2)P(E=2)}}=\frac{\frac{P(D=1|E=1)}{P(D=1|E=2)}}{\frac{P(D=2|E=1)}{P(D=2|E=2)}}=\frac{\frac{P(D=1|E=1)}{P(D=2|E=1)}}{\frac{P(D=1|E=2)}{P(D=2|E=2)}}.
$$

When analyzing these data with Jags, we could still put a $Beta(1,1)$. 

Here, however, we discuss another strategy.

### Incorporate Existing prior information ###

We can incorporate prior information, perhaps based on a
previous case-control study that is similar to the one at hand, by modeling the $\log(OR)$ directly. We need to model both $\theta_1$ and $\theta_2$. So we need to fix two priors.

Hence, we decide to consider a Normal prior on  $\delta=\log(OR)$ and an independent Beta Prior on $\theta_2$. These induce a prior for $(\theta_1, \theta_2)$ by the following transformation

$$
\theta_1=\frac{e^{\delta}\, \theta_2}{1-\theta_2\, (1-e^{\delta})}
$$
To elicit a prior on $\delta$ we think about OR. If our best guess is that OR = 3, then we take the mean of the normal distribution for ) to be log(3) = 1.1. Moreover, if we are, say, 90\% sure that the OR is at least 0.8, then we are also 90% sure that $\log(OR)$ is at least $\log(0.8) = −0.22$. We need to find a normal distribution with a mean of 1.1 and a 10th percentile of −0.22. 

We know (or can look up) that the 10th percentile of a normal is −1.28 standard deviations below the mean, so we set
$$1.1−1.28\sigma = −0.22$$

and solve for 

$\sigma = 1.03$. 

Our prior on $\delta$ is $N(1.1, (1.03)^2)$.

We then set $\theta_2\sim U(0,1)$

```{r}
jags.data=list(n=c(7,16), y=c(7,8), a=1, b=1, mu=log(3), prec=1/(1.03)^2)

bin.model.OR="model{
   for(i in 1:2){ y[i] ~ dbin(theta[i],n[i]) }
   theta[2] ~ dbeta(a,b)
   delta ~ dnorm(mu, prec)
   theta[1] <- exp(delta)*theta[2]/(1-theta[2]*(1-exp(delta)))
   OR <- theta[1]/(1-theta[1])/(theta[2]/(1-theta[2]))
   test_OR=step(OR-1)
}"


jags.param=c("theta", "OR", "test_OR")


jagsfit=jags(data=jags.data, n.chains=1, 
                parameters.to.save=jags.param, n.iter=5000, n.burnin=1000, 
                DIC=TRUE, model.file=textConnection(bin.model.OR))
jagsfit
```





